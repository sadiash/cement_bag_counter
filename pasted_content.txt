I need your help to create a computer vision prototype for a common industrial task: detecting and counting cement bags moving on a conveyor belt from a top-down camera view.

I have several video files that I can provide (or describe the content of) which show the conveyor belt in action with cement bags passing by. These videos represent different conditions: varying lighting, potentially different bag packaging designs, and the conveyor belt operating at different speeds, including starting and stopping.

My goal is a prototype system that can process these videos to:

Detect the individual cement bags as they appear on the conveyor belt.
Track each detected bag as it moves along the belt.
Count the bags that pass a designated point or area in the frame.
Be as generic and robust as possible, given the prototype nature and limited test data, to handle the variations in lighting, bag appearance (within the provided test videos), and conveyor speed/stops.
Constraints & Available Resources:

I will provide video files for testing the prototype. These are test videos, not extensive training datasets covering all possible scenarios.
The camera view is consistently from directly above the conveyor belt.
The system should be able to handle the belt slowing down, speeding up, or stopping temporarily.
Required Output from you:

Prototype Code/Script: Provide a working code script (preferably in Python, using standard libraries like OpenCV, and potentially a deep learning framework like TensorFlow or PyTorch if necessary for detection robustness) that takes a video file as input and processes it.
Instructions: Clear instructions on how to run the code and specify the input video file.
Configuration Guidance: Explain how to define the "counting area" or line in the frame.
Visual Output: The script should ideally output a video file with visualizations (e.g., bounding boxes around detected bags, tracking IDs, the counting line, and the current count displayed).
Final Count: Output the total count of bags detected and tracked across the counting line at the end of the video processing.
Explanation: Briefly explain the approach taken (e.g., what detection method is used, how tracking works, how counting is implemented) and discuss its limitations as a prototype given the potentially limited test data diversity. Suggest what would be needed to make it more production-ready (e.g., more extensive training data for diverse bags/conditions).
Approach Considerations (Suggestions based on common practices):

Consider using pre-trained object detection models (like a generic YOLO or SSD model) and see how well they perform on the cement bags, augmented by tracking. Fine-tuning a model might be beyond the scope if the test videos don't represent sufficient training diversity, but you can suggest this for a production version.
Object tracking algorithms (like SORT, DeepSORT, or others) can help maintain identity across frames and handle speed variations.
Adaptive background subtraction could be a preprocessing step to help isolate moving objects.
Counting can be implemented by tracking objects crossing a defined line or region of interest.
Please provide the most effective prototype you can create based on these requirements, using techniques suitable for handling the described variations with limited test data for development.